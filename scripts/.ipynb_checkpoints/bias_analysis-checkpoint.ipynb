{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-likelihood",
   "metadata": {},
   "source": [
    "# Setting configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter your root dir location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root\n",
    "# -configs\n",
    "# -outputs\n",
    "# train_net.py\n",
    "# README.md\n",
    "root_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace dict value with your checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2weight={\n",
    "    '2dtan/activitynet/baseline_bert': 4,\n",
    "    '2dtan/activitynet/baseline': 3,\n",
    "    '2dtan/charades/baseline_bert': 10,\n",
    "    '2dtan/charades/baseline': 12,\n",
    "    'lgi/activitynet/baseline_bert': 300,\n",
    "    'lgi/activitynet/baseline': 300,\n",
    "    'lgi/charades/baseline_bert': 500,\n",
    "    'lgi/charades/baseline': 500,\n",
    "    'cmin/activitynet/baseline_bert': 12,\n",
    "    'cmin/activitynet/baseline': 7,\n",
    "    'cmin/charades/baseline': 10,\n",
    "    'cmin/tacos/baseline_bert': 5,\n",
    "    'cmin/tacos/baseline': 8,\n",
    "    'fian/activitynet/baseline_bert': 6,\n",
    "    'fian/activitynet/baseline': 6,\n",
    "    'fian/charades/baseline_bert': 15,\n",
    "    'fian/charades/baseline': 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fullname = {\n",
    "    'activitynet': 'Activitynet-Captions',\n",
    "    'charades': 'Charades-STA',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(candidates, gt):\n",
    "    start, end = candidates[0], candidates[1]\n",
    "    s, e = gt[0], gt[1]\n",
    "    # print(s.dtype, start.dtype)\n",
    "    inter = min(end, e) - max(start, s)\n",
    "    union = max(end, e) - min(start, s)\n",
    "    return np.clip(inter, 0., 1.) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',600)\n",
    "sns.set(font=\"DejaVu Sans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-private",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testset\n",
    "testset_moment = {}\n",
    "testset_duration = {}\n",
    "testset_mean_duration = {}\n",
    "dataset_name = {'activitynet' : 'activitynet1.3', 'charades' : 'charades_sta'}\n",
    "for dataset in ['activitynet', 'charades']:\n",
    "    with open(os.path.join(root_dir, f'datasets/{dataset_name[dataset]}/annotations/test.json'), 'r') as F:\n",
    "        data = json.load(F)\n",
    "    dataset_ious = []\n",
    "    dataset_s = []\n",
    "    dataset_e = []\n",
    "    mean_duration = []\n",
    "    for vid, anno in tqdm(data.items()):\n",
    "        duration = anno['duration'] if dataset != 'tacos' else anno['num_frames']/anno['fps']\n",
    "        mean_duration.append(duration)\n",
    "        testset_duration[vid] = duration\n",
    "        for idx in range(len(anno['timestamps'])):\n",
    "            timestamp = anno['timestamps'][idx]\n",
    "            sentence = anno['sentences'][idx]\n",
    "            moment = np.array([max(timestamp[0], 0), min(timestamp[1], duration)]) if dataset != 'tacos' \\\n",
    "            else np.array(\n",
    "                    [max(timestamp[0]/anno['fps'],0), \n",
    "                    min(timestamp[1]/anno['fps'],duration)]\n",
    "                )\n",
    "            moment_normed = moment/duration\n",
    "            dataset_s.append(moment_normed[0])\n",
    "            dataset_e.append(moment_normed[1])\n",
    "            moment_perturbed = np.clip(moment_normed + (np.random.rand(2)-0.5)*0.01, 0., 1.)\n",
    "            dataset_ious.append(iou(moment_perturbed, moment_normed))\n",
    "            sent2moment = testset_moment.get(vid, {})\n",
    "            if sentence in sent2moment:\n",
    "                #print(f'{vid}: {sentence}')\n",
    "                #print(sent2moment[sentence])\n",
    "                continue\n",
    "            else:\n",
    "                sent2moment[sentence] = moment_normed\n",
    "            testset_moment[vid] = sent2moment\n",
    "    dataset_s = np.array(dataset_s)\n",
    "    dataset_e = np.array(dataset_e)\n",
    "    dataset_ious = np.array(dataset_ious)\n",
    "    testset_mean_duration[dataset] = sum(mean_duration)/len(mean_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = []\n",
    "dataset_list = []\n",
    "lm_list = []\n",
    "vid_list = []\n",
    "duration_list = []\n",
    "sentence_list = []\n",
    "iou_list = []\n",
    "s_list = []\n",
    "e_list = []\n",
    "s_norm_list = []\n",
    "e_norm_list = []\n",
    "\n",
    "for method in ['lgi', '2dtan', 'fian', 'cmin']:\n",
    "    for dataset in ['activitynet', 'charades']:\n",
    "        for language_model in ['GloVe']:\n",
    "            if not exist_model(method, dataset):\n",
    "                continue\n",
    "            if language_model == 'GloVe':\n",
    "                model = 'baseline'\n",
    "            else:\n",
    "                model = f'baseline_{language_model}'\n",
    "            model_name = f'{method}/{dataset}/{model}'\n",
    "            weight_epoch = model2weight[model_name]\n",
    "            try:\n",
    "                log_dir = os.path.join(root_dir, f'outputs/{method}/{dataset}/{model}', f'eval_{dataset}_test_original_test_results.pkl')\n",
    "                with open(log_dir, 'rb') as F:\n",
    "                    data = pickle.load(F)\n",
    "            except:\n",
    "                try:\n",
    "                    log_dir = os.path.join(root_dir, f'outputs/{method}/{dataset}/{model}', 'test_results.pkl')\n",
    "                    with open(log_dir, 'rb') as F:\n",
    "                        data = pickle.load(F)\n",
    "                except:\n",
    "                    log_dir = os.path.join(root_dir, f'outputs/{method}/{dataset}/{model}', f'1_{weight_epoch}e_test_results.pkl')\n",
    "                    with open(log_dir, 'rb') as F:\n",
    "                        data = pickle.load(F)\n",
    "            num_result = len(data['vid'])\n",
    "            for i in range(num_result):\n",
    "                duration = testset_duration[vid]\n",
    "                vid = data['vid'][i]\n",
    "                sent = data['sentence'][i]\n",
    "                method_list.append(method.upper())\n",
    "                dataset_list.append(f'{dataset_fullname[dataset]}')\n",
    "                lm_list.append(language_model)\n",
    "                vid_list.append(vid)\n",
    "                duration_list.append(testset_moment[vid][sent][1]-testset_moment[vid][sent][0])\n",
    "                sentence_list.append(sent)\n",
    "                iou_list.append(data['iou'][i].item())\n",
    "                s_norm_list.append(testset_moment[vid][sent][0])\n",
    "                e_norm_list.append(testset_moment[vid][sent][1])\n",
    "                s_list.append(testset_moment[vid][sent][0]*duration)\n",
    "                e_list.append(testset_moment[vid][sent][1]*duration)\n",
    "            print(f'{method} {dataset} {model} completed!')\n",
    "res = pd.DataFrame(\n",
    "    {\n",
    "        'method': method_list,\n",
    "        'dataset': dataset_list,\n",
    "        'LM': lm_list,\n",
    "        'vid': vid_list,\n",
    "        'sentence': sentence_list,\n",
    "        'iou': iou_list,\n",
    "        'duration_normed': duration_list,\n",
    "        's_norm': s_norm_list,\n",
    "        'e_norm': e_norm_list,\n",
    "        's': s_list,\n",
    "        'e': e_list\n",
    "    }\n",
    ")\n",
    "anet_vid = list(set(res[res['dataset']=='activitynet']['vid']))\n",
    "cha_vid = list(set(res[res['dataset']=='charades']['vid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-produce",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-burns",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_norm_thr = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['end_in_tail'] = res['e_norm']>e_norm_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['axes.xmargin'] = 1\n",
    "g = sns.FacetGrid(\n",
    "    data=res[(res['LM']=='GloVe') & (res['dataset']!=f'TACoS')],\n",
    "    row=\"dataset\", col=\"method\",\n",
    "    margin_titles=True,\n",
    ")\n",
    "g.map_dataframe(\n",
    "    sns.scatterplot,\n",
    "    x=\"s_norm\", y=\"iou\",\n",
    "    hue='end_in_tail',\n",
    "    palette=\"icefire\",\n",
    "    hue_norm=(-0.5, 1.5),\n",
    "    s=4,\n",
    "    linewidth=0,\n",
    "    alpha=1,\n",
    ")\n",
    "# Edit axis\n",
    "g.set_axis_labels('GT start time $\\mathbf{s_{gt}}$', 'IoU', fontsize=12, fontweight='bold')\n",
    "g.set_titles(col_template=\"Model {col_name}\", row_template=\"{row_name}\\n\", size=14, fontweight='bold')\n",
    "g.set(xlim=[0,1], ylim=[0,1])\n",
    "# Edit legend\n",
    "g.add_legend(loc='upper right', title='GT end time $e_{gt}$', fontsize=12, bbox_to_anchor=(0.966, 1))\n",
    "new_labels = [f'$e\\in[0.0, {e_norm_thr}]$', f'$e\\in[{e_norm_thr}, 1.0]$']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "# Edit subplot\n",
    "g.fig.subplots_adjust(wspace=.1, hspace=.1)\n",
    "for (row_val, col_val), ax in g.axes_dict.items():\n",
    "    if not exist_model(col_val, row_val):\n",
    "        ax.set_facecolor(\".90\")\n",
    "    else:\n",
    "        ax.set_facecolor((0, 0, 0, 0))\n",
    "# Edit the whole plot\n",
    "g.fig.subplots_adjust(top=0.85)\n",
    "#g.fig.suptitle('IoU - Moment GT Start Time', fontsize=20)\n",
    "g.savefig(\"IoU_s_all.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-fifteen",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_chosen = 'FIAN'\n",
    "dataset_chosen = 'Activitynet-Captions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "g = sns.scatterplot(\n",
    "    data=res[(res['LM']=='GloVe') & (res['dataset']==dataset_chosen) & (res['method']==method_chosen)],\n",
    "    x=\"s_norm\", y=\"iou\", \n",
    "    hue='end_in_tail',\n",
    "    palette=\"icefire\",\n",
    "    hue_norm=(-0.5, 1.5),\n",
    "    s=4,\n",
    "    linewidth=0,\n",
    "    alpha=1,\n",
    "    legend=True,\n",
    ")\n",
    "# Edit axis\n",
    "g.set(xlim=[0,1], ylim=[0,1])\n",
    "legend_labels, _= g.get_legend_handles_labels()\n",
    "g.legend(\n",
    "    legend_labels, [f'[0.0, {e_norm_thr}]', f'[{e_norm_thr}, 1.0]'], \n",
    "    title='GT end time $e$', \n",
    "    bbox_to_anchor=(0.1,1), fontsize=12, ncol=2,\n",
    "    frameon=False # remove border of legend box\n",
    ")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel('Test Sample GT Start Time', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('IoU', fontsize=14, fontweight='bold')\n",
    "\n",
    "g.get_figure().savefig('IoU_s_fian_anet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "g = sns.scatterplot(\n",
    "    data=res[(res['LM']=='GloVe') & (res['dataset']==dataset_chosen) & (res['e_norm']>e_norm_thr) & (res['method']==method_chosen)],\n",
    "    x=\"s_norm\", y=\"iou\", \n",
    "    s=4,\n",
    "    linewidth=0,\n",
    "    alpha=1,\n",
    ")\n",
    "# Edit axis\n",
    "g.set(xlim=[0,1], ylim=[0,1])\n",
    "plt.xlabel('moment start point')\n",
    "plt.ylabel('Rank@1 IoU')\n",
    "g.get_figure().savefig('IoU_s_fian_anet_II.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "g = sns.scatterplot(\n",
    "    data=res[(res['LM']=='GloVe') & (res['dataset']==dataset_chosen) & (res['s_norm']<1-e_norm_thr) & (res['method']==method_chosen)],\n",
    "    x=\"e_norm\", y=\"iou\", \n",
    "    s=4,\n",
    "    linewidth=0,\n",
    "    alpha=1\n",
    ")\n",
    "# Edit axis\n",
    "g.set(xlim=[0,1], ylim=[0,1])\n",
    "plt.xlabel('moment end point')\n",
    "plt.ylabel('Rank@1 IoU')\n",
    "g.get_figure().savefig('IoU_e_fian_anet_I.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "g = sns.scatterplot(\n",
    "    data=res[(res['LM']=='GloVe') & (res['dataset']==dataset_chosen) & (res['s_norm']>1-e_norm_thr) & (res['e_norm']<e_norm_thr) & (res['method']==method_chosen)],\n",
    "    x=\"s_norm\", y=\"iou\", \n",
    "    s=4,\n",
    "    linewidth=0,\n",
    "    alpha=1\n",
    ")\n",
    "# Edit axis\n",
    "g.set(xlim=[0,1], ylim=[0,1])\n",
    "plt.xlabel('moment start point')\n",
    "plt.ylabel('Rank@1 IoU')\n",
    "g.get_figure().savefig('IoU_s_fian_anet_III.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
